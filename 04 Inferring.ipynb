{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a7a9c03-d8a2-4ee2-849e-5f019c509ffa",
   "metadata": {},
   "source": [
    "By inferring, we mean the model takes a text as input and performs some sort of anlysis, such as extracting sentiment or names. In traditional ML work, you would have to collect examples with labels and train. But with LLMs, we can just write a prompt, and work with one model/API.\n",
    "\n",
    "In this example, first we work with a product review, and write prompts to figure out the sentiment and emotions, and extract product information. Then, we work with a news article and infer the topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89049803-2edc-48e4-8276-a07490f263d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02237259-0253-42fe-9960-6bfe8b3600f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-4\", temp=0):\n",
    "    \"\"\"\n",
    "    Generate a text completion using the OpenAI API.\n",
    "\n",
    "    Parameters:\n",
    "        prompt (str): The user's prompt or input text.\n",
    "        model (str, optional): The model to use (default is \"gpt-4\").\n",
    "        temp (float, optional): The temperature parameter controlling randomness (default is 0).\n",
    "\n",
    "    Returns:\n",
    "        str: The generated text completion.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \n",
    "         \"content\": prompt}\n",
    "    ]\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temp  \n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "293314e3-de9f-4181-9d1b-ce8a162d8a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_review = f\"\"\"\n",
    "The positive thing is the size. But it lacks the power/heat :-(. Needs to be 500w/1800+ . \n",
    "I noticed that fries and other items take longer in this fryer/not as crispy. It also lacks \n",
    "features that other fryers have .\n",
    "- No mid time flip notification\n",
    "- when time is finished it just shuts down / my other air fryer had a cooling time when timer \n",
    "finished. Meaning the internal fan would keep running until the unit cooled down/this one does \n",
    "Not have that.\n",
    "I would probably prefer my old Big Box air fryers and give up the size of this one.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03914a07-81bc-4c2c-bd18-098755bc1b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the product review is negative.\n"
     ]
    }
   ],
   "source": [
    "# infer sentiment\n",
    "prompt1 = f\"\"\"\n",
    "What is the sentiment of the following product review, which is delimted with triple backticks?\n",
    "\n",
    "Review text: ```{product_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9b44739-0ec1-4844-886d-b108984d5e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n"
     ]
    }
   ],
   "source": [
    "# infer sentiment, and specify its format: one word (positive or negative)\n",
    "prompt2 = f\"\"\"\n",
    "What is the sentiment of the following product review, which is delimted with triple backticks?\n",
    "\n",
    "Give one word response \"positive\" or \"negative\".\n",
    "\n",
    "Review text: ```{product_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt2)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9925543-69e3-4082-8c5f-d36fb7c99c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disappointment, frustration, dissatisfaction, regret, sadness\n"
     ]
    }
   ],
   "source": [
    "# infer emotions in the text\n",
    "prompt3 = f\"\"\"\n",
    "Identify a list of emotions that the writer of the following review is expressing. \n",
    "Include no more than five items in the list. \n",
    "Format your answer as a list of lower-case words seperated by commas.\n",
    "The review is delimted with triple backticks.\n",
    "\n",
    "Review text: ```{product_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt3)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92bf4c2d-1f9d-4246-a275-3c8cd0c6e5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\n"
     ]
    }
   ],
   "source": [
    "# check if a particular emotion (e.g., anger) is present\n",
    "prompt4 = f\"\"\"\n",
    "Is the author of the following review expressing anger?\n",
    "Give your answer as either yes or no.\n",
    "The review is delimted with triple backticks.\n",
    "\n",
    "Review text: ```{product_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt4)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19eaed62-5e8f-4761-8a70-cb56e487afdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Item\": \"air fryer\", \"Brand\": \"unknown\"}\n"
     ]
    }
   ],
   "source": [
    "# extract product information\n",
    "prompt6 = f\"\"\"\n",
    "Identify the following items from the review text:\n",
    "- Product purchased by reviewer\n",
    "- Company that made the product\n",
    "The review id delimted with triple backticks. \n",
    "Formate the response as JSON objec with \"Item\" and \"Brand\" as keyes.\n",
    "If the information isn't present, use \"unknown\" as value.\n",
    "Make the response as sort as possible.\n",
    "\n",
    "Review text: ```{product_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt6)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af95751c-f4c0-4f58-89fd-ccbb4e0f28bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Sentiment\": \"negative\", \"Anger\": false, \"Product\": \"air fryer\", \"Brand\": \"unknown\"}\n"
     ]
    }
   ],
   "source": [
    "# Do it all in one prompt!\n",
    "prompt7 = f\"\"\"\n",
    "Identify the following items from the review text:\n",
    "1. Sentiment(one word answer: positive or negative)\n",
    "2. Is the reviewer expressing anger? (boolean answer: true or false)\n",
    "3. Product purchased by the reviewer\n",
    "4. Company that made the product\n",
    "\n",
    "The reviewer is delimited with triple backticks.\n",
    "Format your response as a JSON object with the following keys:\n",
    "\"Sentiment\", \"Anger\", \"Product\", \"Brand\".\n",
    "If the information is not present, use \"unknown\".\n",
    "\n",
    "Make your response as short as possible.\n",
    "\n",
    "Review text: ```{product_review}```\n",
    "\"\"\"\n",
    "response = get_completion(prompt7)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84a320e0-281b-42e2-8a55-716c5e00751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer the topics of a news article\n",
    "# https://decrypt.co/212793/sam-altman-openai-bill-gates-microsoft\n",
    "news_article = f\"\"\"\n",
    "Sam Altman, securely back at the help of leading global artificial intelligence firm OpenAI, \n",
    "sees largely positive trade offs to technology that is racing quickly to match human intelligence.\n",
    "\n",
    "\"Although we are giving something up here, in some sense we are going to have things that are smarter \n",
    "than us,\" he told tech mogul Bill Gates during a recent podcast conversation, “If we can get into this \n",
    "world of post scarcity, we will find new things to do.”\n",
    "\n",
    "Altman and Gates engaged in an insightful dialogue that netted profound insights, peeling back the \n",
    "layers of Altman's perspectives on AI and its trajectory. But first, Altman sought to reassure \n",
    "industry watchers following the ultimately unsuccessful corporate coup last year.\n",
    "\n",
    "“A lot of people have remarked on the fact that the team has never felt more productive, or more \n",
    "optimistic, or better,\" Altman said.\n",
    "\n",
    "Altman touched upon the philosophical aspects of AI, contemplating a future where AI surpasses human \n",
    "intelligence. He has previously shared his concerns regarding the socioeconomic impact of AI, calling \n",
    "for better regulations that ensure a properly aligned AI development.\n",
    "\n",
    "For Altman, AI will lead to a society in which workers will be able to do more things for the same amount \n",
    "of money, making them more productive for their employers.\n",
    "\n",
    "\"If you make a programmer three times more effective, it's not just that they can write, they can do three \n",
    "times more stuff, it's that they can... think of totally different things,\" he said.\n",
    "\n",
    "For Altman, this shift in the work dynamics that AI is causing is inevitable.\n",
    "\n",
    "“The part that I find potentially a little scary is just the speed with which society is going to have to \n",
    "adapt and that the labor market will change,” he said.\n",
    "\n",
    "Altman previously said that “the hypothetical idea that we already have done something really bad by \n",
    "launching ChatGPT” is something that bothers him. However, as worried as he may sound for the future of \n",
    "those affected by AI, OpenAI is relentlessly pushing the boundaries of its GPT models, presenting more \n",
    "powerful LLMs, a store for customized agents that could easily replace more jobs, and partnering with news \n",
    "sites to train its future GPT-5 model on their content.\n",
    "\n",
    "As for the future of AI, Altman emphasized the need for significant leaps in AI's cognitive skills. For him, \n",
    "multimodality (the capacity of a model to understand inputs that go beyond text, and contain images or videos \n",
    "for example) will play a key role in determining which model dominates the AI race\n",
    "\n",
    "However, the quality of the outputs will be the differentiating factor, and “the most important areas of progress \n",
    "will be around reasoning ability... and also reliability,” he said.\n",
    "\n",
    "Altman and Gates discussed the topic of regulatory and ethical constraints, exploring calls for a cohesive global \n",
    "regulatory framework for AI. Considering the expansive impact of advanced AI systems, he once again advocated for \n",
    "a balanced, international governance approach:\n",
    "\n",
    "\"For these... future extraordinarily powerful systems, we have been socializing the idea of a global regulatory \n",
    "body,\" he said.\n",
    "\n",
    "Altman's reflections present a multifaceted outlook on AI's future: a mix of hope and prudence, ingenuity and \n",
    "accountability. New players in the AI field are challenging OpenAI’s dominance, and regulators (just as everyday \n",
    "workers) are more worried than ever.\n",
    "\n",
    "That doesn’t scare Alman.\n",
    "\n",
    "\"It's, you know, both annoying, motivating and fun,\" he said, “But it does push us to be better and do faster \n",
    "and do things faster.”\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0d24230-c2db-4aa0-9f71-2f2f87cfda2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence, AI Development, Socioeconomic Impact, AI Regulation, Work Dynamics\n",
      "['Artificial Intelligence', ' AI Development', ' Socioeconomic Impact', ' AI Regulation', ' Work Dynamics']\n"
     ]
    }
   ],
   "source": [
    "prompt8 = f\"\"\"\n",
    "Determine five topics that are being discussed in the following text, \n",
    "which is delimited with triple backticks.\n",
    "\n",
    "Make each item one or two words long.\n",
    "\n",
    "Format your response as a list of items seperated by commas.\n",
    "\n",
    "Text: ```{news_article}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt8)\n",
    "print(response)\n",
    "# process as a python list\n",
    "print(response.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fba396c0-7d48-4267-b728-b00cf691df3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"AI\": true,\n",
      "  \"Job Satisfaction\": false,\n",
      "  \"Technology\": true,\n",
      "  \"Global Economy\": false,\n",
      "  \"Federal Government\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Is a particular topic (or a few) present?\n",
    "# Example of zero-shot learning (we did not provide training/labeled data for this classification task!)\n",
    "topic_list = [\"AI\", \"Job Satisfaction\", \"Technology\", \"Global Economy\", \"Federal Government\"]\n",
    "prompt9 = f\"\"\"Determine whether each item in the following list of topics \n",
    "is a topic discussed in the text below. \n",
    "\n",
    "The text is delimited with triple backticks.\n",
    "\n",
    "The list of topics is {\", \".join(topic_list)}\n",
    "\n",
    "Text: ```{news_article}```\n",
    "\n",
    "Format your response as a JSON, where the keys are the topics, \n",
    "and the values are boolean (true or false) values indicating whether \n",
    "that topic is discussed in the text.\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt9)\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
